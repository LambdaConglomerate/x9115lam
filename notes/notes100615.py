# Ada lovelace, child of lord byron
# Taught number theory and algebra to suppress he inner poet
# Babbage working on how to mechanize computation
# Introduced at a party
# Foot notes include invention of loops, programs

# Brunell built paddington station, iron boats

# Differential Evolution is the swiss army knife of optimization
# Mutation operator combines other known solutions
# If there is a constant among the population, invariance in the population, the DE respects it and no mutation occurs	
# Compare the parent and child, the better survives
# Extrapolation among members of the population
# 100s of variants on Differential Evolution
# Elite Sampling, sort the fontier once and pick the best 
# One thing from the parent should be put in the kid
# The invariant: everytime we loop around the list, everything on the pareto frontier will be better than something else
# crossover = 0.3 but if that doesn't work smash it up to 0.8-1
# fiddling parameters of machine learning algs is called hyperparameterization

# Whether trimming or wrapping is the best ideo is a domain decision
# python: range will generate a list, xrange will keep min, max and current pointer

# Paper:
# Domain -> software defect prediction
